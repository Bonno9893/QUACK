# Caso d'Uso Bancario QUACK - File di Configurazione
# 
# Questo file contiene tutti i parametri di configurazione per la pipeline di clustering.
# Copia questo file in 'config.yaml' e aggiorna con le tue impostazioni specifiche.

# Configurazione D-Wave
dwave:
  abilitato: true
  token_api: "IL_TUO_TOKEN_DWAVE"  # Sostituisci con il tuo token effettivo
  risolutore: null  # null per auto-selezione, o specifica il nome del risolutore
  num_letture: 1000  # Numero di letture del quantum annealing
  tempo_annealing: 20  # Tempo di annealing in microsecondi
  forza_catena: null  # null per calcolo automatico
  auto_scala: true  # Scala automaticamente il problema al range hardware
  topologia: "zephyr"  # Topologia preferita: pegasus, zephyr, o chimera

# Configurazione Simulated Annealing
simulated_annealing:
  abilitato: true
  num_letture: 10000  # Numero di iterazioni SA
  num_sweep: 1000  # Sweep per lettura
  range_beta: [0.1, 10.0]  # Range di temperatura
  tipo_schedule_beta: "geometrico"  # geometrico o lineare
  seed: 42  # Seed random per riproducibilità

# Configurazione Gurobi
gurobi:
  abilitato: true
  percorso_licenza: null  # Percorso al file licenza Gurobi (se non in posizione default)
  limite_tempo: 60  # Limite tempo in secondi
  gap_mip: 0.01  # Gap di ottimalità MIP
  thread: 0  # 0 per auto, o numero specifico
  verboso: false  # Mostra output Gurobi

# Percorsi Dati e Output
percorsi:
  file_dati: "dati/clienti_bancari.csv"  # File dati input
  cartella_risultati: "risultati/"  # Directory base per tutti gli output
  cartella_cache: "cache/"  # Directory per caching risultati intermedi

# Configurazione Esperimento
esperimento:
  n_istanze: 10  # Numero di istanze di test da generare
  
  # Parametri generazione istanze
  parametri_istanza:
    n_punti: 50  # Numero di punti per istanza
    n_cluster: 3  # Numero di cluster
    dimensione_cluster_seed: 10  # Dimensione cluster iniziale
    dimensione_espansione: 20  # Punti da aggiungere nell'espansione
    livello_rumore: 0.1  # Rumore nei dati sintetici (0-1)
    
  # Parametri ottimizzazione lambda
  range_lambda: [0.1, 10.0]  # Range per ricerca lambda
  campioni_lambda: 20  # Numero di valori lambda da testare
  metodo_ottimizzazione_lambda: "adattivo"  # adattivo o ricerca_griglia
  
  # Metriche di valutazione
  metriche:
    - "ari"  # Indice di Rand Aggiustato
    - "silhouette"  # Coefficiente silhouette
    - "davies_bouldin"  # Indice Davies-Bouldin
    - "calinski_harabasz"  # Indice Calinski-Harabasz
    
  # Impostazioni benchmark
  benchmark:
    esecuzioni_ripetute: 3  # Numero di volte per ripetere ogni esperimento
    esecuzioni_riscaldamento: 1  # Esecuzioni di riscaldamento prima del timing
    salva_soluzioni: true  # Salva tutti i dettagli delle soluzioni
    salva_embedding: false  # Salva informazioni embedding quantistico

# Impostazioni Visualizzazione
visualizzazione:
  crea_grafici: true
  formato_grafici: "png"  # png, pdf, o svg
  dpi: 300  # Risoluzione per formati raster
  stile: "seaborn"  # stile matplotlib
  
  # Grafici specifici da generare
  grafici:
    - "confronto_performance"
    - "analisi_scalabilita"
    - "ottimizzazione_lambda"
    - "qualita_soluzione"
    - "statistiche_embedding"
    - "landscape_energia"

# Configurazione Logging
logging:
  livello: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: "pipeline.log"  # Percorso file log
  formato: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  output_console: true  # Stampa anche su console
  
# Impostazioni Avanzate
avanzate:
  # Processamento parallelo
  parallelo:
    abilitato: false  # Usa processamento parallelo dove possibile
    n_job: -1  # Numero di job paralleli (-1 per tutte le CPU)
    backend: "multiprocessing"  # multiprocessing o threading
  
  # Caching
  cache:
    abilitato: true  # Cache risultati intermedi
    ttl: 3600  # Tempo di vita cache in secondi
    
  # Gestione errori
  gestione_errori:
    continua_su_errore: false  # Continua pipeline su errori risolutore
    max_tentativi: 3  # Massimi tentativi per operazioni fallite
    delay_tentativi: 5  # Delay tra tentativi in secondi
  
  # Limiti risorse
  limiti_risorse:
    max_memoria_gb: 16  # Uso massimo memoria
    timeout_secondi: 3600  # Timeout globale per pipeline
    
  # Riproducibilità
  riproducibilita:
    seed: 42  # Seed random globale
    deterministico: true  # Usa algoritmi deterministici dove possibile
    salva_dati_grezzi: false  # Salva campioni quantistici grezzi

# Impostazioni Notifiche (opzionale)
notifiche:
  abilitate: false
  email:
    server_smtp: "smtp.gmail.com"
    porta_smtp: 587
    mittente: "tua_email@gmail.com"
    password: "tua_password"
    destinatari: ["destinatario@esempio.com"]
  
  # Quando inviare notifiche
  invia_su:
    - "completamento"  # Completamento pipeline
    - "errore"  # Errore pipeline
    - "milestone"  # Milestone maggiori

# Impostazioni API (per servire risultati)
api:
  abilitata: false
  host: "0.0.0.0"
  porta: 8000
  apri_browser_auto: true
  
# Impostazioni Export
export:
  formati:
    - "csv"  # Esporta risultati come CSV
    - "json"  # Esporta come JSON
    - "excel"  # Esporta come Excel
    - "pickle"  # Esporta come pickle per Python
  
  # Cosa esportare
  include:
    - "metriche"  # Metriche performance
    - "soluzioni"  # Dettagli soluzioni
    - "configurazioni"  # Configurazione esperimento
    - "tempistiche"  # Informazioni temporali dettagliate
